{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Proximity Trees\n",
    "This is an algorithm made up by Bart Goethals. It doesn't exist yet. It's bsed on another algorithm created for other purposes.\n",
    "\n",
    "You can read section 3 of [this paper](https://arxiv.org/pdf/1808.10594.pdf) (skip 3.1).\n",
    "Lucas, B., Shifaz, A., Pelletier, C., O’Neill, L., Zaidi, N., Goethals, B., ... & Webb, G. I. (2019). Proximity forest: an effective and scalable distance-based classifier for time series. Data Mining and Knowledge Discovery, 33(3), 607-635."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Branch:\n",
    "    def __init__(self, exemplar, class_label, subtree):\n",
    "        self.exemplar = exemplar  # An object, if from a node it is closest to this exemplar, it goes to given tree\n",
    "        self.subtree = subtree  # Should be an internal node or a leaf node\n",
    "\n",
    "        self.class_label = class_label  # The class label of the leaf node, not required for the algorithm, but might be useful for debuggin\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def print(self, depth):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class InternalNode(TreeNode):\n",
    "    def __init__(self, data_x, data_y, groups, depth, max_depth, splits_to_sample):\n",
    "        assert len(data_x) == len(data_y) == len(groups)\n",
    "        assert len(data_x) > 0\n",
    "\n",
    "        depth += 1\n",
    "\n",
    "        self.measure = lambda x, y: np.linalg.norm(x - y)\n",
    "        self.branches = []  # Contains internal nodes or leaf nodes\n",
    "\n",
    "        exemplars, closest_exemplars = get_split(data_x, data_y, groups, splits_to_sample, self.measure)\n",
    "\n",
    "        for i, exemplar in enumerate(exemplars):\n",
    "            closest_data_x = data_x[closest_exemplars == i]\n",
    "            closest_data_y = data_y[closest_exemplars == i]\n",
    "            closest_data_groups = groups[closest_exemplars == i]\n",
    "\n",
    "            if len(closest_data_x) == 0:\n",
    "                # If everything is closer to the other one, you don't need to create a node with 0 data points\n",
    "                continue\n",
    "\n",
    "            subtree = get_node(closest_data_x, closest_data_y, closest_data_groups, depth, max_depth, splits_to_sample)\n",
    "            self.branches.append(Branch(exemplar, i, subtree))  # TODO: Fix label somewhere here instead of i\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Return the label of the closest subtree to the data point\n",
    "        exemplar_distance = [self.measure(data, branch.exemplar) for branch in self.branches]\n",
    "        closest_exemplars = get_closest_exemplars(exemplar_distance, [data], self.measure)\n",
    "        branch = self.branches[closest_exemplars[0]]\n",
    "        return branch.subtree.predict(data)\n",
    "\n",
    "    def print(self, depth):\n",
    "        for branch in self.branches:\n",
    "            print(f\"{'-' * depth}Exemplar ({branch.class_label}): \" + str(branch.exemplar))\n",
    "            branch.subtree.print(depth + 1)\n",
    "\n",
    "\n",
    "# if all data reaching a node has the same class (node is pure), create_leaf function creates a new leaf node and assigns this class lbel to its field class\n",
    "class LeafNode(TreeNode):\n",
    "    def __init__(self, class_label):\n",
    "        self.class_label = class_label  # This label is assigned to all data reaching this node\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.class_label\n",
    "\n",
    "    def print(self, depth):\n",
    "        print(f\"{'-' * depth}Leaf ({self.class_label})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Splitting criteriaa\n",
    "class ProximityTreeClassifier:\n",
    "    def __init__(self, max_depth=5, num_features_to_keep=None, splits_to_sample=10):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.num_features_to_keep = num_features_to_keep\n",
    "        self.features_to_use_indices = None\n",
    "        self.splits_to_sample = splits_to_sample\n",
    "\n",
    "    def fit(self, data_x, data_y, groups):\n",
    "\n",
    "        self.num_features = data_x.shape[1]  # Total number of features, not the number used!!!\n",
    "\n",
    "        self.features_to_use_indices = np.random.choice(len(data_x[0]), self.num_features_to_keep,\n",
    "                                                        replace=False) if self.num_features_to_keep is not None else np.arange(\n",
    "            len(data_x[0]))\n",
    "        data_x_reduced = subsample_features(data_x, self.features_to_use_indices)\n",
    "        # TODO: Reduce features inpredict\n",
    "        self.root = get_node(data_x_reduced, data_y, groups, depth=0, max_depth=self.max_depth,\n",
    "                             splits_to_sample=self.splits_to_sample)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Convert data to numpy array if not yet the case\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            data = np.array(data)\n",
    "        # If data is 1d, add a dimension to make it 2d\n",
    "        if data.ndim == 1:\n",
    "            data = data[np.newaxis, :]\n",
    "        assert self.root is not None, \"You must fit the model before predicting\"\n",
    "        assert data.shape[\n",
    "                   1] == self.num_features, \"The number of features in the data must match the number of features in the training data\"\n",
    "        data_reduced = subsample_features(data, self.features_to_use_indices)\n",
    "        predictions = np.apply_along_axis(self.root.predict, 1, data_reduced)\n",
    "        assert predictions.shape[0] == data.shape[0], \"The number of predictions must match the number of data points\"\n",
    "        return predictions\n",
    "\n",
    "    def print(self):\n",
    "        self.root.print(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def is_pure(data_y):\n",
    "    # Check if all data has the same class label\n",
    "    unique_y = np.unique(data_y)\n",
    "    return len(unique_y) == 1\n",
    "\n",
    "\n",
    "def get_most_common_element(array):\n",
    "    return np.argmax(np.bincount(array))\n",
    "\n",
    "\n",
    "def subsample_features(data_x, feature_indices):\n",
    "    return data_x[:, feature_indices]\n",
    "\n",
    "\n",
    "def get_node(data_x, data_y, groups, depth, max_depth, splits_to_sample):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) > 0\n",
    "\n",
    "    if is_pure(data_y) or depth >= max_depth:\n",
    "        # class_label = data_y.iloc[0] # must use iloc here to get element of first row and not element at index 0\n",
    "        class_label = get_most_common_element(data_y)\n",
    "        return LeafNode(class_label)\n",
    "    else:\n",
    "        return InternalNode(data_x, data_y, groups, depth, max_depth, splits_to_sample)\n",
    "\n",
    "\n",
    "# Some util functions\n",
    "def random_pick_row(data):\n",
    "    return data[np.random.randint(0, data.shape[0])]\n",
    "    # return np.random.choice(group_x_with_label) # Can't use this for 2d arrays\n",
    "\n",
    "\n",
    "def get_from_group_if_exists_else_random(group_x, group_y, data_x, data_y, label):\n",
    "    # Get all elements of group_x where group_y == label\n",
    "    group_x_with_label = group_x[group_y == label]\n",
    "    if group_x_with_label.size != 0:\n",
    "        # sample random with same label\n",
    "        return random_pick_row(group_x_with_label)\n",
    "    else:\n",
    "        # If none exist, return a random element from data_x where data_y == label\n",
    "        data_x_with_label = data_x[data_y == label]\n",
    "        return random_pick_row(data_x_with_label)\n",
    "\n",
    "\n",
    "def get_group_data(data_x, data_y, groups, group_id):\n",
    "    random_group_indices = np.where(groups == group_id)[0]\n",
    "    group_x = np.take(data_x, random_group_indices)\n",
    "    group_y = np.take(data_y, random_group_indices)\n",
    "    return group_x, group_y\n",
    "\n",
    "\n",
    "def get_single_split(data_x, data_y, groups):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) != 0\n",
    "\n",
    "    # Sample uniformly any of the groups\n",
    "    # Get the unique values in groups\n",
    "    unique_groups = np.unique(groups)\n",
    "    random_group = np.random.choice(unique_groups)\n",
    "\n",
    "    random_group_x, random_group_y = get_group_data(data_x, data_y, groups, random_group)\n",
    "\n",
    "    assert len(random_group_x) == len(random_group_y) != 0\n",
    "\n",
    "    exemplar_winner = get_from_group_if_exists_else_random(random_group_x, random_group_y, data_x, data_y, 1)\n",
    "    exemplar_loser = get_from_group_if_exists_else_random(random_group_x, random_group_y, data_x, data_y, 0)\n",
    "    exemplars = [exemplar_loser, exemplar_winner]\n",
    "\n",
    "    return exemplars\n",
    "\n",
    "\n",
    "def gini(y, classes):\n",
    "    # Code from https://stackoverflow.com/questions/64741099/how-to-calculate-gini-index-using-two-numpy-arrays\n",
    "    if not y.shape[0]:\n",
    "        return 0\n",
    "\n",
    "    probs = []\n",
    "    for cls in classes:\n",
    "        probs.append((y == cls).sum() / y.shape[0])  # For each class c in classes compute class probabilities\n",
    "\n",
    "    p = np.array(probs)\n",
    "    return 1 - ((p * p).sum())\n",
    "\n",
    "\n",
    "def tree_gini_index(Y_left, Y_right):\n",
    "    classes = (0, 1)\n",
    "\n",
    "    # Code from https://stackoverflow.com/questions/64741099/how-to-calculate-gini-index-using-two-numpy-arrays\n",
    "    N = Y_left.shape[0] + Y_right.shape[0]\n",
    "    p_L = Y_left.shape[0] / N\n",
    "    p_R = Y_right.shape[0] / N\n",
    "\n",
    "    return p_L * gini(Y_left, classes) + p_R * gini(Y_right, classes)\n",
    "\n",
    "\n",
    "def get_split(data_x, data_y, groups, splits_to_sample, distance_measure):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) != 0\n",
    "\n",
    "    min_gini_index = np.inf\n",
    "    for split in range(splits_to_sample):\n",
    "        exemplars = get_single_split(data_x, data_y, groups)\n",
    "\n",
    "        closest_exemplars = get_closest_exemplars(exemplars, data_x, distance_measure)\n",
    "        data_splits = []\n",
    "        # empty_split = False\n",
    "        for i, exemplar in enumerate(exemplars):\n",
    "            closest_data_y = data_y[closest_exemplars == i]\n",
    "            data_splits.append(closest_data_y)\n",
    "\n",
    "            # if len(closest_data_y) == 0:\n",
    "            #     empty_split = True\n",
    "            #     break\n",
    "\n",
    "        # if empty_split:\n",
    "        #     continue\n",
    "\n",
    "        gini_index = tree_gini_index(data_splits[0], data_splits[1])\n",
    "\n",
    "        if gini_index < min_gini_index:\n",
    "            min_gini_index = gini_index\n",
    "            best_exemplars = exemplars\n",
    "            best_closest_exemplars = closest_exemplars\n",
    "\n",
    "    # if min_gini_index == np.inf:\n",
    "    #     # If no split was found (all containing an empty split), return None\n",
    "    #     return None, None\n",
    "\n",
    "    return best_exemplars, best_closest_exemplars\n",
    "\n",
    "\n",
    "def get_distance_to_exemplars(data_x_row, exemplars, measure):\n",
    "    return [measure(data_x_row, exemplar) for exemplar in exemplars]\n",
    "\n",
    "\n",
    "def get_closest_exemplars(exemplars, data, measure):\n",
    "    # Return the index of the exemplar that is closest to the data point\n",
    "    distances = [get_distance_to_exemplars(data_row, exemplars, measure) for data_row in data]\n",
    "    closest_exemplar_indices = np.argmin(distances, axis=1)\n",
    "    assert len(closest_exemplar_indices) == len(data)\n",
    "    return closest_exemplar_indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test\n",
    "Just some random data example for debugging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_x = np.array([[0, 1, 0], [1, 0, 1], [0, 0, 0],  # 3 headlines for test 0\n",
    "                   [1, 0, 0], [1, 1, 0], [0, 1, 1]])  # 3 headlines for test 1\n",
    "\n",
    "data_y = np.array([0, 1, 0,  # test 0\n",
    "                   1, 0, 0])  # test 1\n",
    "\n",
    "groups = np.array([0, 0, 0,  # test 0\n",
    "                   1, 1, 1])  # test 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Exemplar (0): 0\n",
      "-Exemplar (0): 1\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 0 0]\n",
      "--Exemplar (0): [0 0 0]\n",
      "---Exemplar (0): [0 0 0]\n",
      "----Exemplar (0): 0\n",
      "-----Leaf (0)\n",
      "----Exemplar (1): [1 0 0]\n",
      "-----Leaf (1)\n",
      "Exemplar (1): 1\n",
      "-Exemplar (0): [1 1 0]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): 1\n",
      "--Exemplar (0): 0\n",
      "---Leaf (0)\n",
      "--Exemplar (1): [1 0 1]\n",
      "---Leaf (1)\n"
     ]
    }
   ],
   "source": [
    "model = ProximityTreeClassifier()\n",
    "model.fit(data_x, data_y, groups)\n",
    "\n",
    "model.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 0, 1, 0, 0])"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0, 1, 1], [1, 0, 0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More test\n",
    "Let's take a larger test dataset from the real data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "from util import get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True,\n",
    "                                                              full_y_test=True)\n",
    "test_y_features = get_manually_labeled_features(test_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_sm = train_x.head(7).to_numpy()\n",
    "train_y_sm = train_y.head(7)['Winner'].astype(int).to_numpy()\n",
    "groups_sm = groups.head(7).to_numpy()\n",
    "train_x_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplar (0): [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-Exemplar (0): [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "--Exemplar (0): [1 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "---Leaf (0)\n",
      "--Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "---Exemplar (0): [1 1 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
      "----Leaf (0)\n",
      "---Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "----Leaf (1)\n",
      "Exemplar (1): [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-Exemplar (0): [1 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "--Leaf (1)\n"
     ]
    }
   ],
   "source": [
    "model = ProximityTreeClassifier()\n",
    "model.fit(train_x_sm, train_y_sm, groups_sm)\n",
    "model.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n       [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_x_sm = test_x.head(4).to_numpy()\n",
    "test_x_features_only = get_manually_labeled_features(test_x.head(4)).to_numpy()\n",
    "test_y_sm = test_y.head(4)['Winner']\n",
    "groups_test_sm = test_x.head(4)['Test'].to_numpy()\n",
    "\n",
    "assert train_x_sm.shape[1] == test_x_features_only.shape[1]  # same number of features\n",
    "\n",
    "test_x_features_only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/3883669348.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_x_features_only\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_y_sm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroups_test_sm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Test {group} prediction: {prediction}, actual: {y}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m         \u001B[0mtree_predictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m         \u001B[0mmost_occuring\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_along_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_most_common_element\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtree_predictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mmost_occuring\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36mget_predictions\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for x, y, group in zip(test_x_features_only, test_y_sm, groups_test_sm):\n",
    "    prediction = model.predict(x)\n",
    "    print(f'Test {group} prediction: {prediction}, actual: {y}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This results in all the same predictions (all 0 or all 1) most of the time. (might be just coïncidence, it's also possible to predict the other number):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ProximityForestClassifier:\n",
    "    def __init__(self, n_trees=100, show_progress=True, use_bootstrapping=True, reduce_features=True,\n",
    "                 sample_multiple_splits=10, max_depth=5):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []\n",
    "        self.classes_ = None\n",
    "        self.show_progress = show_progress\n",
    "        self.use_bootstrapping = use_bootstrapping\n",
    "        self.reduce_features = reduce_features\n",
    "        self.sample_multiple_splits = sample_multiple_splits\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, data_x, data_y, groups):\n",
    "        data_x = self.preprocess_data(data_x)\n",
    "        data_y = self.preprocess_data(data_y.astype(int))\n",
    "        groups = self.preprocess_data(groups)\n",
    "\n",
    "        # multithreaded\n",
    "        iterator = tqdm(range(self.n_trees), disable=not self.show_progress, desc='Fitting')\n",
    "        self.trees = Parallel(n_jobs=32)(delayed(self.fit_tree)(data_x, data_y, groups) for i in iterator)\n",
    "\n",
    "        self.classes_ = np.unique(data_y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_tree(self, data_x, data_y, groups):\n",
    "        if self.use_bootstrapping:\n",
    "            data_x_bootstrap, data_y_bootstrap, groups_bootstrap = self.bootstrap(data_x, data_y, groups)\n",
    "        else:\n",
    "            data_x_bootstrap, data_y_bootstrap, groups_bootstrap = data_x, data_y, groups\n",
    "\n",
    "        if self.reduce_features:\n",
    "            num_features_to_keep = int(np.sqrt(data_x_bootstrap.shape[1]))\n",
    "        else:\n",
    "            num_features_to_keep = None\n",
    "            # assert num_features_to_keep <= len(data_x[0])\n",
    "\n",
    "        return ProximityTreeClassifier(num_features_to_keep=num_features_to_keep,\n",
    "                                       splits_to_sample=self.sample_multiple_splits, max_depth=self.max_depth)\\\n",
    "            .fit(data_x_bootstrap, data_y_bootstrap, groups_bootstrap)\n",
    "\n",
    "    def bootstrap(self, data_x, data_y, groups):\n",
    "        # Bootstrap some rows\n",
    "        indices = np.random.choice(len(data_x), size=int(len(data_x) * 0.1), replace=True)\n",
    "        data_x_bootstrap = data_x[indices]\n",
    "        data_y_bootstrap = data_y[indices]\n",
    "        groups_bootstrap = groups[indices]\n",
    "        return data_x_bootstrap, data_y_bootstrap, groups_bootstrap\n",
    "\n",
    "    def get_predictions(self, data):\n",
    "        data = self.preprocess_data(data)\n",
    "\n",
    "        iterator = tqdm(range(self.n_trees), disable=not self.show_progress, desc='Predicting')\n",
    "        predictions = Parallel(n_jobs=32)(delayed(self.trees[i].predict)(data) for i in iterator)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        # if data is a pandas dataframe, convert to numpy array\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.replace({True: 1, False: 0})\n",
    "            data = data.to_numpy()\n",
    "        if isinstance(data, pd.Series):\n",
    "            data = data.replace({True: 1, False: 0})\n",
    "            data = data.to_numpy()\n",
    "        return data\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        tree_predictions = self.get_predictions(data)\n",
    "        return np.mean(tree_predictions, axis=0)\n",
    "\n",
    "    def predict(self, data):\n",
    "        tree_predictions = self.get_predictions(data)\n",
    "        most_occuring = np.apply_along_axis(get_most_common_element, 0, tree_predictions)\n",
    "        return most_occuring\n",
    "        # Get most occuring element for each column\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_most_common_element(array):\n",
    "    return np.argmax(np.bincount(array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ProximityForestClassifier()\n",
    "model.fit(train_x_sm, train_y_sm, groups_sm)\n",
    "model.predict(test_x_features_only)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True,\n",
    "                                                              full_y_test=True)\n",
    "test_x_features = get_manually_labeled_features(test_x)\n",
    "\n",
    "model = ProximityForestClassifier()\n",
    "model.fit(train_x, train_y[\"Winner\"], groups)\n",
    "model.predict_proba(test_x_features)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Not all numbers are 0 (but quite a lot). This will hopefully be fixed once i add bagging and random subspace method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.15% (84/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without any bootstrpping or random subspace sampling, the accuracy is slightly better than random Accuracy: 46.15% (84/182) (+5%)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bootstrapping\n",
    "The code above has been updated to use bootstrapping. This means that for each tree we will sample a random subset of the data and use that to train the tree."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:07<00:00, 70.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.20% (95/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! Adding bootstrapping improved the accuracy by +7%. Accuracy: 53.30% (97/182)\n",
    "We're also using a lot less samples per tree (randomly sampling 10% of the dataset size for each tree)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random subspace sampling\n",
    "The code above has been updated to use random subspace sampling. For each internal node, we're only going to look at sqrt(num_features) features instead of all of them. Which features we look at per node, will randomly be fixed during training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:06<00:00, 79.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.49% (101/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy: 55.49% (101/182). Again a slight increase, let's take a look at how bootstrapping without random subspace sampling works:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:47<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.75% (96/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500, use_bootstrapping=False)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy: 52.75% (96/182). An increase similar to the size of the increase of bootstrapping."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample multiple splits (select using gini)\n",
    "The code above has been updated to not just take a random test as split, but sample multiple tests and use the one with the lowest gini impurity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:10<00:00, 47.00it/s]\n",
      "Predicting: 100%|██████████| 500/500 [00:22<00:00, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.34% (108/182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters\n",
    "Just some playing around, still need to do a better search."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting: 100%|██████████| 32/32 [00:00<00:00, 175.82it/s]\n",
      "Predicting: 100%|██████████| 32/32 [00:00<00:00, 16001.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.95% (100/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=32)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [00:00<00:00, 452.58it/s]\n",
      "Predicting: 100%|██████████| 100/100 [00:04<00:00, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.40% (98/182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=100)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 1000/1000 [00:25<00:00, 39.68it/s]\n",
      "Predicting: 100%|██████████| 1000/1000 [00:46<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.24% (106/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=1000)\n",
    "fit_predict_print_wp(model, train_x, train_y,\n",
    "                     test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Better search\n",
    "The hyperparameters we want to optimize are: n_trees, sample_multiple_splits and max_depth."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from util import get_winners_only, predict_wp, evaluate_wp, get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x_full, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=False)\n",
    "train_x = get_manually_labeled_features(train_x_full)\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "\n",
    "def objective_cv(space):\n",
    "    # Change al floats in the space dict to ints\n",
    "    for key in space:\n",
    "        space[key] = int(space[key])\n",
    "\n",
    "    model = ProximityForestClassifier(show_progress=False, **space)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for train_index, val_index in group_kfold.split(train_x, train_y, groups=train_x_full['Test']):\n",
    "        train_x_small, train_y_small = train_x_full.iloc[train_index], train_y.iloc[train_index]\n",
    "        val_x, val_y = train_x_full.iloc[val_index], get_winners_only(train_y.iloc[val_index])\n",
    "        groups_train = train_x_full.iloc[train_index]['Test']\n",
    "\n",
    "        accuracy = fit_predict_print_wp(model, train_x_small, train_y_small,\n",
    "                     val_x, val_y, groups=groups_train, multiple_class_names=False, silent=True)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        break # Skip cross validation, only use one fold\n",
    "\n",
    "    accuracy_mean = np.mean(accuracies)\n",
    "    print(f\"Accuracy mean: {accuracy_mean} for parameters {space}\")\n",
    "\n",
    "    return {'loss': -accuracy_mean, 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 5, 'n_trees': 96, 'sample_multiple_splits': 18}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 63, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 5, 'n_trees': 91, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 9, 'n_trees': 160, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 3, 'n_trees': 102, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.512396694214876 for parameters {'max_depth': 3, 'n_trees': 49, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5537190082644629 for parameters {'max_depth': 2, 'n_trees': 54, 'sample_multiple_splits': 17}\n",
      "Accuracy mean: 0.5509641873278237 for parameters {'max_depth': 5, 'n_trees': 81, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 9, 'n_trees': 176, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 8, 'n_trees': 146, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 5, 'n_trees': 127, 'sample_multiple_splits': 17}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 3, 'n_trees': 175, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5041322314049587 for parameters {'max_depth': 8, 'n_trees': 46, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.6033057851239669 for parameters {'max_depth': 4, 'n_trees': 117, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5840220385674931 for parameters {'max_depth': 7, 'n_trees': 42, 'sample_multiple_splits': 13}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 10, 'n_trees': 84, 'sample_multiple_splits': 1}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 8, 'n_trees': 156, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5537190082644629 for parameters {'max_depth': 5, 'n_trees': 52, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 5, 'n_trees': 51, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 7, 'n_trees': 191, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 4, 'n_trees': 128, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5371900826446281 for parameters {'max_depth': 2, 'n_trees': 73, 'sample_multiple_splits': 1}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 4, 'n_trees': 113, 'sample_multiple_splits': 1}\n",
      "Accuracy mean: 0.6033057851239669 for parameters {'max_depth': 6, 'n_trees': 115, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 6, 'n_trees': 136, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5068870523415978 for parameters {'max_depth': 6, 'n_trees': 111, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 4, 'n_trees': 122, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 6, 'n_trees': 139, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 4, 'n_trees': 104, 'sample_multiple_splits': 20}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 3, 'n_trees': 98, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5068870523415978 for parameters {'max_depth': 7, 'n_trees': 67, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 6, 'n_trees': 154, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 4, 'n_trees': 167, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 91, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 2, 'n_trees': 119, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 5, 'n_trees': 136, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5950413223140496 for parameters {'max_depth': 3, 'n_trees': 33, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 10, 'n_trees': 196, 'sample_multiple_splits': 20}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 9, 'n_trees': 146, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 6, 'n_trees': 105, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 3, 'n_trees': 90, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 4, 'n_trees': 79, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5509641873278237 for parameters {'max_depth': 5, 'n_trees': 181, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 7, 'n_trees': 63, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 8, 'n_trees': 128, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 2, 'n_trees': 165, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 5, 'n_trees': 147, 'sample_multiple_splits': 18}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 3, 'n_trees': 110, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 6, 'n_trees': 95, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 8, 'n_trees': 74, 'sample_multiple_splits': 16}\n",
      "100%|██████████| 50/50 [06:29<00:00,  7.80s/trial, best loss: -0.6033057851239669]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'max_depth': 4.0, 'n_trees': 117.0, 'sample_multiple_splits': 4.0}"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe\n",
    "\n",
    "space = {\n",
    "    'n_trees': hp.quniform('n_trees', 32, 200, 1), # Chosen to keep this low to speed up the search\n",
    "    'sample_multiple_splits': hp.quniform('sample_multiple_splits', 1, 20, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 2, 10, 1),\n",
    "}\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(fn=objective_cv,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=50,\n",
    "                   trials=trials)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy mean: 0.6033057851239669 for parameters {'max_depth': 4, 'n_trees': 117, 'sample_multiple_splits': 4}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting: 100%|██████████| 117/117 [00:00<00:00, 1257.76it/s]\n",
      "Predicting: 100%|██████████| 117/117 [00:00<00:00, 1170.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.55% (92/182)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "\n",
    "best_params = {'max_depth': 4, 'n_trees': 117, 'sample_multiple_splits': 4}\n",
    "model = ProximityForestClassifier(**best_params)\n",
    "\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hmm, this is not good. Let's try changing the hyperparameter search space:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 26, 'n_trees': 227, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 475, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 12, 'n_trees': 255, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 32, 'n_trees': 268, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 9, 'n_trees': 406, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 28, 'n_trees': 250, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5647382920110193 for parameters {'max_depth': 32, 'n_trees': 341, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5426997245179064 for parameters {'max_depth': 26, 'n_trees': 206, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 12, 'n_trees': 209, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 7, 'n_trees': 264, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 13, 'n_trees': 299, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 25, 'n_trees': 395, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 5, 'n_trees': 385, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 370, 'sample_multiple_splits': 13}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 20, 'n_trees': 328, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 10, 'n_trees': 417, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 20, 'n_trees': 203, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 19, 'n_trees': 437, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 16, 'n_trees': 341, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 12, 'n_trees': 206, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5537190082644629 for parameters {'max_depth': 23, 'n_trees': 140, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5509641873278237 for parameters {'max_depth': 21, 'n_trees': 152, 'sample_multiple_splits': 6}\n",
      " 44%|████▍     | 22/50 [17:42<18:42, 40.09s/trial, best loss: -0.5867768595041323]"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe\n",
    "\n",
    "space = {\n",
    "    'n_trees': hp.quniform('n_trees', 128, 512, 1), # Chosen to keep this low to speed up the search\n",
    "    'sample_multiple_splits': hp.quniform('sample_multiple_splits', 2, 16, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 4, 32, 1),\n",
    "}\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(fn=objective_cv,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=50,\n",
    "                   trials=trials)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}