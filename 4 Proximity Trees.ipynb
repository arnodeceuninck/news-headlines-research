{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Proximity Trees\n",
    "This is an algorithm made up by Bart Goethals. It doesn't exist yet. It's bsed on another algorithm created for other purposes.\n",
    "\n",
    "You can read section 3 of [this paper](https://arxiv.org/pdf/1808.10594.pdf) (skip 3.1).\n",
    "Lucas, B., Shifaz, A., Pelletier, C., O’Neill, L., Zaidi, N., Goethals, B., ... & Webb, G. I. (2019). Proximity forest: an effective and scalable distance-based classifier for time series. Data Mining and Knowledge Discovery, 33(3), 607-635."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Branch:\n",
    "    def __init__(self, exemplar, class_label, subtree):\n",
    "        self.exemplar = exemplar  # An object, if from a node it is closest to this exemplar, it goes to given tree\n",
    "        self.subtree = subtree  # Should be an internal node or a leaf node\n",
    "\n",
    "        self.class_label = class_label  # The class label of the leaf node, not required for the algorithm, but might be useful for debuggin\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def print(self, depth):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class InternalNode(TreeNode):\n",
    "    def __init__(self, data_x, data_y, groups, depth, max_depth):\n",
    "        assert len(data_x) == len(data_y) == len(groups)\n",
    "        assert len(data_x) > 0\n",
    "\n",
    "        depth += 1\n",
    "\n",
    "        self.measure = lambda x, y: np.linalg.norm(x - y)\n",
    "        self.branches = []  # Contains internal nodes or leaf nodes\n",
    "\n",
    "        exemplars = get_split(data_x, data_y, groups)\n",
    "\n",
    "        closest_exemplars = get_closest_exemplars(exemplars, data_x, self.measure)\n",
    "        for i, exemplar in enumerate(exemplars):\n",
    "            # Find the data items that are closest to the exemplar (and thus having i in the closest_exemplars array)\n",
    "            closest_data_x = data_x[closest_exemplars == i]\n",
    "            closest_data_y = data_y[closest_exemplars == i]\n",
    "            closest_data_groups = groups[closest_exemplars == i]\n",
    "\n",
    "            if len(closest_data_x) == 0:\n",
    "                # If everything is closer to the other one, you don't need to create a node with 0 data points\n",
    "                continue\n",
    "\n",
    "            subtree = get_node(closest_data_x, closest_data_y, closest_data_groups, depth, max_depth)\n",
    "            self.branches.append(Branch(exemplar, i, subtree))  # TODO: Fix label somewhere here instead of i\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Return the label of the closest subtree to the data point\n",
    "        exemplar_distance = [self.measure(data, branch.exemplar) for branch in self.branches]\n",
    "        closest_exemplars = get_closest_exemplars(exemplar_distance, [data], self.measure)\n",
    "        branch = self.branches[closest_exemplars[0]]\n",
    "        return branch.subtree.predict(data)\n",
    "\n",
    "    def print(self, depth):\n",
    "        for branch in self.branches:\n",
    "            print(f\"{'-' * depth}Exemplar ({branch.class_label}): \" + str(branch.exemplar))\n",
    "            branch.subtree.print(depth + 1)\n",
    "\n",
    "\n",
    "# if all data reaching a node has the same class (node is pure), create_leaf function creates a new leaf node and assigns this class lbel to its field class\n",
    "class LeafNode(TreeNode):\n",
    "    def __init__(self, class_label):\n",
    "        self.class_label = class_label  # This label is assigned to all data reaching this node\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.class_label\n",
    "\n",
    "    def print(self, depth):\n",
    "        print(f\"{'-' * depth}Leaf ({self.class_label})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "\n",
    "# Splitting criteriaa\n",
    "class ProximityTreeClassifier:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, data_x, data_y, groups):\n",
    "        self.root = get_node(data_x, data_y, groups, depth=0, max_depth=self.max_depth)\n",
    "        self.num_features = data_x.shape[1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Convert data to numpy array if not yet the case\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            data = np.array(data)\n",
    "        # If data is 1d, add a dimension to make it 2d\n",
    "        if data.ndim == 1:\n",
    "            data = data[np.newaxis, :]\n",
    "        assert self.root is not None, \"You must fit the model before predicting\"\n",
    "        assert data.shape[\n",
    "                   1] == self.num_features, \"The number of features in the data must match the number of features in the training data\"\n",
    "        predictions = np.apply_along_axis(self.root.predict, 1, data)\n",
    "        assert predictions.shape[0] == data.shape[0], \"The number of predictions must match the number of data points\"\n",
    "        return predictions\n",
    "\n",
    "    def print(self):\n",
    "        self.root.print(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "def is_pure(data_y):\n",
    "    # Check if all data has the same class label\n",
    "    unique_y = np.unique(data_y)\n",
    "    return len(unique_y) == 1\n",
    "\n",
    "def get_most_common_element(array):\n",
    "    return np.argmax(np.bincount(array))\n",
    "\n",
    "def get_node(data_x, data_y, groups, depth, max_depth):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) > 0\n",
    "\n",
    "    if is_pure(data_y) or depth >= max_depth:\n",
    "        # class_label = data_y.iloc[0] # must use iloc here to get element of first row and not element at index 0\n",
    "        class_label = get_most_common_element(data_y)\n",
    "        return LeafNode(class_label)\n",
    "    else:\n",
    "        return InternalNode(data_x, data_y, groups, depth, max_depth)\n",
    "\n",
    "\n",
    "# Some util functions\n",
    "def random_pick_row(data):\n",
    "    return data[np.random.randint(0, data.shape[0])]\n",
    "    # return np.random.choice(group_x_with_label) # Can't use this for 2d arrays\n",
    "\n",
    "\n",
    "def get_from_group_if_exists_else_random(group_x, group_y, data_x, data_y, label):\n",
    "    # Get all elements of group_x where group_y == label\n",
    "    group_x_with_label = group_x[group_y == label]\n",
    "    if group_x_with_label.size != 0:\n",
    "        # sample random with same label\n",
    "        return random_pick_row(group_x_with_label)\n",
    "    else:\n",
    "        # If none exist, return a random element from data_x where data_y == label\n",
    "        data_x_with_label = data_x[data_y == label]\n",
    "        return random_pick_row(data_x_with_label)\n",
    "\n",
    "\n",
    "def get_split(data_x, data_y, groups):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) != 0\n",
    "\n",
    "    # Sample uniformly any of the groups\n",
    "    # Get the unique values in groups\n",
    "    unique_groups = np.unique(groups)\n",
    "    random_group = np.random.choice(unique_groups)\n",
    "\n",
    "    # get the elements of data_x and data_y at the indices of the random group\n",
    "    random_group_indices = np.where(groups == random_group)[0]\n",
    "    # random_group_x = data_x[random_group_indices]\n",
    "    # random_group_y = data_y[random_group_indices] # Gave some strange errors, trying take instead\n",
    "    random_group_x = np.take(data_x, random_group_indices)\n",
    "    random_group_y = np.take(data_y, random_group_indices)\n",
    "\n",
    "    assert len(random_group_x) == len(random_group_y) != 0\n",
    "\n",
    "    exemplar_winner = get_from_group_if_exists_else_random(random_group_x, random_group_y, data_x, data_y, 1)\n",
    "    exemplar_loser = get_from_group_if_exists_else_random(random_group_x, random_group_y, data_x, data_y, 0)\n",
    "    exemplars = [exemplar_loser, exemplar_winner]\n",
    "\n",
    "    return exemplars\n",
    "\n",
    "\n",
    "def get_distance_to_exemplars(data_x_row, exemplars, measure):\n",
    "    return [measure(data_x_row, exemplar) for exemplar in exemplars]\n",
    "\n",
    "\n",
    "def get_closest_exemplars(exemplars, data, measure):\n",
    "    # Return the index of the exemplar that is closest to the data point\n",
    "    distances = [get_distance_to_exemplars(data_row, exemplars, measure) for data_row in data]\n",
    "    closest_exemplar_indices = np.argmin(distances, axis=1)\n",
    "    assert len(closest_exemplar_indices) == len(data)\n",
    "    return closest_exemplar_indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test\n",
    "Just some random data example for debugging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_x = np.array([[0, 1, 0], [1, 0, 1], [0, 0, 0],  # 3 headlines for test 0\n",
    "                   [1, 0, 0], [1, 1, 0], [0, 1, 1]])  # 3 headlines for test 1\n",
    "\n",
    "data_y = np.array([0, 1, 0,  # test 0\n",
    "                   1, 0, 0])  # test 1\n",
    "\n",
    "groups = np.array([0, 0, 0,  # test 0\n",
    "                   1, 1, 1])  # test 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Exemplar (0): 0\n",
      "-Exemplar (0): 1\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 0 0]\n",
      "--Exemplar (0): [0 0 0]\n",
      "---Exemplar (0): [0 0 0]\n",
      "----Exemplar (0): 0\n",
      "-----Leaf (0)\n",
      "----Exemplar (1): [1 0 0]\n",
      "-----Leaf (1)\n",
      "Exemplar (1): 1\n",
      "-Exemplar (0): [1 1 0]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): 1\n",
      "--Exemplar (0): 0\n",
      "---Leaf (0)\n",
      "--Exemplar (1): [1 0 1]\n",
      "---Leaf (1)\n"
     ]
    }
   ],
   "source": [
    "model = ProximityTreeClassifier()\n",
    "model.fit(data_x, data_y, groups)\n",
    "\n",
    "model.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 0, 1, 0, 0])"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0, 1, 1], [1, 0, 0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More test\n",
    "Let's take a larger test dataset from the real data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "from util import get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True,\n",
    "                                                              full_y_test=True)\n",
    "test_y_features = get_manually_labeled_features(test_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_sm = train_x.head(7).to_numpy()\n",
    "train_y_sm = train_y.head(7)['Winner'].astype(int).to_numpy()\n",
    "groups_sm = groups.head(7).to_numpy()\n",
    "train_x_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplar (0): [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-Exemplar (0): [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "--Exemplar (0): [1 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "---Leaf (0)\n",
      "--Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "---Exemplar (0): [1 1 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
      "----Leaf (0)\n",
      "---Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "----Leaf (1)\n",
      "Exemplar (1): [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-Exemplar (0): [1 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "--Leaf (1)\n"
     ]
    }
   ],
   "source": [
    "model = ProximityTreeClassifier()\n",
    "model.fit(train_x_sm, train_y_sm, groups_sm)\n",
    "model.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n       [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_x_sm = test_x.head(4).to_numpy()\n",
    "test_x_features_only = get_manually_labeled_features(test_x.head(4)).to_numpy()\n",
    "test_y_sm = test_y.head(4)['Winner']\n",
    "groups_test_sm = test_x.head(4)['Test'].to_numpy()\n",
    "\n",
    "assert train_x_sm.shape[1] == test_x_features_only.shape[1]  # same number of features\n",
    "\n",
    "test_x_features_only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/3883669348.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_x_features_only\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_y_sm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroups_test_sm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Test {group} prediction: {prediction}, actual: {y}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m         \u001B[0mtree_predictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m         \u001B[0mmost_occuring\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_along_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_most_common_element\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtree_predictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mmost_occuring\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36mget_predictions\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for x, y, group in zip(test_x_features_only, test_y_sm, groups_test_sm):\n",
    "    prediction = model.predict(x)\n",
    "    print(f'Test {group} prediction: {prediction}, actual: {y}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This results in all the same predictions (all 0 or all 1) most of the time. (might be just coïncidence, it's also possible to predict the other number):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ProximityForestClassifier:\n",
    "    def __init__(self, n_trees=10):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, data_x, data_y, groups):\n",
    "        data_x = self.preprocess_data(data_x)\n",
    "        data_y = self.preprocess_data(data_y.astype(int))\n",
    "        groups = self.preprocess_data(groups)\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            self.trees.append(ProximityTreeClassifier().fit(data_x, data_y, groups))\n",
    "        return self\n",
    "\n",
    "    def get_predictions(self, data):\n",
    "        data = self.preprocess_data(data)\n",
    "        return [self.trees[i].predict(data) for i in range(self.n_trees)]\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        # if data is a pandas dataframe, convert to numpy array\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.replace({True: 1, False: 0})\n",
    "            data = data.to_numpy()\n",
    "        return data\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        tree_predictions = self.get_predictions(data)\n",
    "        return np.mean(tree_predictions, axis=0)\n",
    "\n",
    "    def predict(self, data):\n",
    "        tree_predictions = self.get_predictions(data)\n",
    "        most_occuring = np.apply_along_axis(get_most_common_element, 0, tree_predictions)\n",
    "        return most_occuring\n",
    "        # Get most occuring element for each column\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "def get_most_common_element(array):\n",
    "    return np.argmax(np.bincount(array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ProximityForestClassifier()\n",
    "model.fit(train_x_sm, train_y_sm, groups_sm)\n",
    "model.predict(test_x_features_only)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0. , 0.1, 0. , 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1, 0.1, 0. , 0.1, 0. ,\n       0. , 0. , 0. , 0.1, 0. , 0. , 0.1, 0. , 0. , 0.1, 0. , 0. , 0. ,\n       0.1, 0. , 0.1, 0. , 0. , 0.1, 0. , 0. , 0. , 0.1, 0. , 0. , 0.1,\n       0.1, 0. , 0. , 0. , 0.1, 0. , 0.1, 0.1, 0. , 0. , 0. , 0.1, 0. ,\n       0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0.1, 0. , 0.1, 0. , 0. , 0. ,\n       0.1, 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0.1, 0. , 0. , 0. ,\n       0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0. , 0. , 0.1, 0.1, 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. ,\n       0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0.1, 0.1, 0.1, 0.1, 0. , 0. , 0. , 0. , 0.1, 0.1, 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1,\n       0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0.1, 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0.1, 0. , 0. , 0. ,\n       0. , 0. , 0.1, 0.1, 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0.1, 0.1, 0.1, 0. , 0.1, 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1, 0. , 0. ,\n       0. , 0. , 0.1, 0.1, 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0.1, 0.1, 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. ,\n       0.1, 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0. ,\n       0. , 0. , 0.1, 0. , 0.1, 0.1, 0.1, 0.1, 0.1, 0. , 0. , 0. , 0. ,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1, 0.1, 0. ,\n       0. , 0.1, 0. , 0.1, 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.8,\n       0.8, 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n       0. , 0. , 0.1, 0.1, 0.1, 0. , 0. , 0. , 0. , 0.1, 0.1, 0. , 0.1,\n       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. ,\n       0. , 0.1, 0. , 0.1, 0. , 0. , 0.1, 0. , 0.1, 0. , 0. , 0. , 0. ,\n       0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1, 0.1])"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True,\n",
    "                                                              full_y_test=True)\n",
    "test_x_features = get_manually_labeled_features(test_x)\n",
    "\n",
    "model = ProximityForestClassifier()\n",
    "model.fit(train_x, train_y[\"Winner\"], groups)\n",
    "model.predict_proba(test_x_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}