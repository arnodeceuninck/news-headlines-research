{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Combinations\n",
    "Let's combine the different extra features that gave better results and see whether this improves the overall performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from util import get_wpm_train_test, get_label_columns\n",
    "\n",
    "train_x_full, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=False)\n",
    "\n",
    "features = get_label_columns()  # initially only the manual labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from util import add_length_to_dataframe\n",
    "features.append(\"Length\")\n",
    "train_x_full = add_length_to_dataframe(train_x_full)\n",
    "test_x = add_length_to_dataframe(test_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba717f17247e48e4813dd844c3b8df54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6096948c80a421aa58d00eb055ae7fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import add_headline_embedding_to_dataframe\n",
    "train_x_full, extra_features = add_headline_embedding_to_dataframe(train_x_full)\n",
    "test_x, _ = add_headline_embedding_to_dataframe(test_x)\n",
    "features += extra_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from util import add_diff_length\n",
    "features.append('NumWordsDiff')\n",
    "features.append('AvgWordLengthDiff')\n",
    "features.append('MaxWordLengthDiff')\n",
    "train_x_full = add_diff_length(train_x_full)\n",
    "test_x = add_diff_length(test_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.59% (103/182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:525: FutureWarning: Pass `sample_weight` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.20% (95/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_evaluate_extra_features, get_xgboost_importance\n",
    "_, model_xgb = fit_predict_evaluate_extra_features(train_x_full, train_y, test_x, test_y, features, groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from util import get_winners_only, predict_wp, evaluate_wp\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "train_x_full.reset_index(drop=True, inplace=True)\n",
    "train_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def objective_cv(space):\n",
    "    if 'max_depth' in space:\n",
    "        space['max_depth'] = int(space['max_depth'])\n",
    "\n",
    "    model = XGBClassifier(**space)\n",
    "\n",
    "    accuracies = []\n",
    "    for train_index, val_index in group_kfold.split(train_x_full, train_y, groups=train_x_full['Test']):\n",
    "\n",
    "        train_x_small, train_y_small = train_x_full.iloc[train_index], train_y.iloc[train_index]\n",
    "        val_x, val_y = train_x_full.iloc[val_index], get_winners_only(train_y.iloc[val_index])\n",
    "        # groups_val = train_x_full.iloc[val_index]['Test']\n",
    "\n",
    "        model.fit(train_x_small[features], train_y_small['Winner']) #, groups_val, sample_weight=None, verbose=0)\n",
    "\n",
    "        predicted_winners = predict_wp(model, val_x, features=features)\n",
    "\n",
    "        assert len(predicted_winners) == len(val_y)\n",
    "\n",
    "        accuracy = evaluate_wp(val_y, predicted_winners)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    accuracy_mean = np.mean(accuracies)\n",
    "    print(f\"Accuracy mean: {accuracy_mean} for parameters {space}\")\n",
    "\n",
    "    return {'loss': -accuracy_mean, 'status': STATUS_OK, 'loss_variance': np.var(accuracies, ddof=1)} # Added var based on this article https://www.databricks.com/blog/2021/04/15/how-not-to-tune-your-model-with-hyperopt.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "space = {\n",
    "    'reg_alpha': hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "    'gamma': hp.uniform('gamma', 1, 9),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 2, 8, 1),\n",
    "    'n_estimators': 500,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raise \"Takes a long time to run\"\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(fn=objective_cv,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=100,\n",
    "                   trials=trials)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Without embedding\n",
    "\n",
    "100%|██████████| 100/100 [04:04<00:00,  2.44s/trial, best loss: -0.5605668398677375]\n",
    "\n",
    "{'colsample_bytree': 0.660947785503167,\n",
    " 'gamma': 1.009721450628837,\n",
    " 'learning_rate': 0.15887155111036247,\n",
    " 'max_depth': 6.0,\n",
    " 'reg_alpha': 40.0,\n",
    " 'reg_lambda': 0.47894997446546944}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For some reason does this take way longer than when running this in chapter 2e, even though I think the only difference were the extra features I've added. But we added way more extra features, which makes sense why it takes so long. I'm first searching hyper parameters without embeded headline, since this is a lot faster."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "best_params = {'colsample_bytree': 0.660947785503167,\n",
    " 'gamma': 1.009721450628837,\n",
    " 'learning_rate': 0.15887155111036247,\n",
    " 'max_depth': 6,\n",
    " 'reg_alpha': 40.0,\n",
    " 'reg_lambda': 0.47894997446546944}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:525: FutureWarning: Pass `sample_weight` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.40% (98/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp\n",
    "\n",
    "model = XGBClassifier(n_estimators=500, random_state=42, **best_params)\n",
    "fit_predict_print_wp(model, train_x_full, train_y, test_x, test_y, groups=train_x_full['Test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.35260273972602735 for parameters {'colsample_bytree': 0.7664073804072375, 'gamma': 4.400556660788374, 'learning_rate': 0.04599037810814008, 'max_depth': 2, 'n_estimators': 500, 'reg_alpha': 154.0, 'reg_lambda': 0.5808846315837922}\n",
      "Accuracy mean: 0.35260273972602735 for parameters {'colsample_bytree': 0.9417813439836679, 'gamma': 1.3343461247034236, 'learning_rate': 0.12882358325375412, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 174.0, 'reg_lambda': 0.6386074504849956}\n",
      "Accuracy mean: 0.5633915918752953 for parameters {'colsample_bytree': 0.5246147262298059, 'gamma': 1.360691548360549, 'learning_rate': 0.023337422631523323, 'max_depth': 4, 'n_estimators': 500, 'reg_alpha': 52.0, 'reg_lambda': 0.9079866239641216}\n",
      "Accuracy mean: 0.4406991025035428 for parameters {'colsample_bytree': 0.6713526584957731, 'gamma': 8.835077982448018, 'learning_rate': 0.17267689900847327, 'max_depth': 7, 'n_estimators': 500, 'reg_alpha': 101.0, 'reg_lambda': 0.8749143432884918}\n",
      "Accuracy mean: 0.4972508266414738 for parameters {'colsample_bytree': 0.6154665108193801, 'gamma': 3.4678633594319317, 'learning_rate': 0.18463817827164372, 'max_depth': 4, 'n_estimators': 500, 'reg_alpha': 107.0, 'reg_lambda': 0.08781099738394649}\n",
      "Accuracy mean: 0.5495418044402457 for parameters {'colsample_bytree': 0.5006983177882374, 'gamma': 5.882926008536023, 'learning_rate': 0.016431063664094043, 'max_depth': 4, 'n_estimators': 500, 'reg_alpha': 48.0, 'reg_lambda': 0.42932193508294647}\n",
      "Accuracy mean: 0.35260273972602735 for parameters {'colsample_bytree': 0.5973017196289153, 'gamma': 1.153239175694245, 'learning_rate': 0.16590739814092267, 'max_depth': 7, 'n_estimators': 500, 'reg_alpha': 164.0, 'reg_lambda': 0.5574735030463992}\n",
      "Accuracy mean: 0.5165044874822862 for parameters {'colsample_bytree': 0.5179602470827389, 'gamma': 3.963101058398795, 'learning_rate': 0.1614716517037883, 'max_depth': 7, 'n_estimators': 500, 'reg_alpha': 85.0, 'reg_lambda': 0.5943059515967009}\n",
      "Accuracy mean: 0.510987246102976 for parameters {'colsample_bytree': 0.9927879191001863, 'gamma': 8.20608530614082, 'learning_rate': 0.1952198569030847, 'max_depth': 5, 'n_estimators': 500, 'reg_alpha': 52.0, 'reg_lambda': 0.3941929383294305}\n",
      "Accuracy mean: 0.5068493150684932 for parameters {'colsample_bytree': 0.6178760571702036, 'gamma': 5.886562873930126, 'learning_rate': 0.01862215999736846, 'max_depth': 4, 'n_estimators': 500, 'reg_alpha': 73.0, 'reg_lambda': 0.49700148677051104}\n",
      "100%|██████████| 10/10 [09:11<00:00, 55.15s/trial, best loss: -0.5633915918752953]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'colsample_bytree': 0.5246147262298059,\n 'gamma': 1.360691548360549,\n 'learning_rate': 0.023337422631523323,\n 'max_depth': 4.0,\n 'reg_alpha': 52.0,\n 'reg_lambda': 0.9079866239641216}"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try with embedding\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(fn=objective_cv,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=10,\n",
    "                   trials=trials)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "100%|██████████| 10/10 [09:11<00:00, 55.15s/trial, best loss: -0.5633915918752953]\n",
    "\n",
    "{'colsample_bytree': 0.5246147262298059,\n",
    " 'gamma': 1.360691548360549,\n",
    " 'learning_rate': 0.023337422631523323,\n",
    " 'max_depth': 4.0,\n",
    " 'reg_alpha': 52.0,\n",
    " 'reg_lambda': 0.9079866239641216}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "best_params = {'colsample_bytree': 0.5246147262298059,\n",
    " 'gamma': 1.360691548360549,\n",
    " 'learning_rate': 0.023337422631523323,\n",
    " 'max_depth': 4,\n",
    " 'reg_alpha': 52.0,\n",
    " 'reg_lambda': 0.9079866239641216}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:525: FutureWarning: Pass `sample_weight` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.04% (102/182)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=500, random_state=42, **best_params)\n",
    "fit_predict_print_wp(model, train_x_full, train_y, test_x, test_y, groups=train_x_full['Test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}