{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multi Layer Perceptron Classifier\n",
    "Let's try some neural networks and start with an [MLP classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.04% (102/182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from util import get_wpm_train_test, fit_predict_print_wp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train_x, train_y, test_x, test_y = get_wpm_train_test()\n",
    "model = MLPClassifier(random_state=42)\n",
    "\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy is again slightly higher, now also slightly better than our RandomClassifier but nothing significant (+1.90%). Note: When taking the average RandomClassifier score for multiple runs, we have an increase of +14.97%.\n",
    "Since we're getting an error that it hasn't converged, we can try to increase the number of iterations:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.59% (103/182)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42, max_iter=1000)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy has slightly increased (only +0.55%) and the warning has disappeared."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25772/1511419368.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Fitting 5 folds for each of 900 candidates, totalling 4500 fits\"\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Prevent accidentially running this\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[1;32mraise\u001B[0m \u001B[0mKeyboardInterrupt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMLPClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m42\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Fitting 5 folds for each of 900 candidates, totalling 4500 fits\")  # Prevent accidentially running this\n",
    "raise KeyboardInterrupt\n",
    "\n",
    "model = MLPClassifier(random_state=42)\n",
    "\n",
    "# Parameters suggested by co-pilot\n",
    "param_grid = {'hidden_layer_sizes': [(100,), (50,), (25,), (10,), (5,)],\n",
    "              'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "              'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "              'max_iter': [1000]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_search.fit(train_x, train_y[\"Winner\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'activation': 'identity',\n 'alpha': 0.0001,\n 'hidden_layer_sizes': (10,),\n 'learning_rate': 'constant',\n 'max_iter': 1000,\n 'solver': 'adam'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params = grid_search.best_params_\n",
    "best_params = {'activation': 'identity',\n",
    "               'alpha': 0.0001,\n",
    "               'hidden_layer_sizes': (10,),\n",
    "               'learning_rate': 'constant',\n",
    "               'max_iter': 1000,\n",
    "               'solver': 'adam'}\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So the best parmeters are as follows:\n",
    "\n",
    "{'activation': 'identity',\n",
    " 'alpha': 0.0001,\n",
    " 'hidden_layer_sizes': (10,),\n",
    " 'learning_rate': 'constant',\n",
    " 'max_iter': 1000,\n",
    " 'solver': 'adam'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.49% (101/182)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42, **best_params)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even though we provided more optimization parameters, our accuracy is slightly lower on the test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLPRegressor\n",
    "A regressor tries to predict a number, while a classifier tries to predict a class. We want to predict a score that represents how good a headline is, in order to select the best (so something between a number and aa class)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.85% (98/182)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(random_state=42)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, proba=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'alpha': 0.05, 'hidden_layer_sizes': (100, 1), 'max_iter': 1000}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some params based from here: https://stackoverflow.com/questions/61163759/tuning-mlpregressor-hyper-parameters\n",
    "param_grid = {'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100, 1)],\n",
    "              'alpha': [0.0001, 0.001, 0.05],\n",
    "              'max_iter': [1000]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, verbose=1)\n",
    "\n",
    "# train_x_int = train_x.replace({False: 0, True: 1})\n",
    "# train_y_int = train_y.replace({False: 0, True: 1})\n",
    "\n",
    "grid_search.fit(train_x, train_y[\"Winner\"])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So the best parameters are as follows:\n",
    "\n",
    "{'alpha': 0.05, 'hidden_layer_sizes': (100, 1), 'max_iter': 1000}\n",
    "\n",
    "Let's test them:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.85% (98/182)\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42, **best_params)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, proba=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Those hyperparameters doesn't seem to make any difference. Let's try some more:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'alpha': 1, 'hidden_layer_sizes': (200,), 'max_iter': 1000}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes': [(50,), (100,), (200,), (100, 100, 100)],\n",
    "              'alpha': [0.05, 0.1, 1],\n",
    "              'max_iter': [1000]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(train_x, train_y[\"Winner\"])\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.30% (97/182)\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42, **best_params)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, proba=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like it keeps going for larger hidden layers (200,) and alpha (1), but the accuracy on the test set hs still slightly decreased. Let's still try some higher parameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "{'alpha': 1, 'hidden_layer_sizes': (200,), 'max_iter': 1000}\n",
      "Accuracy: 53.30% (97/182)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes': [(200,), (400), (800)],\n",
    "              'alpha': [1,2,4,8],\n",
    "              'max_iter': [1000]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(train_x, train_y[\"Winner\"])\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "model = MLPRegressor(random_state=42, **best_params)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, proba=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alright, it sticks with the previous parameters now (but still has worse results than the MLPClassifier, which has also lower results than the Naïve Bayes Classifier)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}